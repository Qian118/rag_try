# 导入必要的库
import sys
from catboost import CatBoostClassifier, CatBoostRegressor
from imblearn.over_sampling import RandomOverSampler
import lightgbm as lgb
import matplotlib.pyplot as plt
import numpy as np
import optuna
import pandas as pd
import plotly.express as px
import seaborn as sns
from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.manifold import TSNE
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import log_loss
from sklearn.metrics import make_scorer, mean_squared_error
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, GroupKFold, RepeatedStratifiedKFold
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB, CategoricalNB, GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from tqdm import tqdm
import xgboost as xgb
from xgboost import plot_importance
from ydata_profiling import ProfileReport

# 设置pandas显示选项和seaborn配色方案
pd.set_option('display.max_columns', None)  # 显示所有列
sns.set_palette(sns.color_palette("Set2"))  # 设置颜色主题

# 打印Python版本信息
print(f"Running on {sys.version}")

# 控制是否生成数据报告的标志
GENERATE_REPORTS = False

# 环境判断标志(是否为Kaggle环境)
KAGGLE_ENV = True
if KAGGLE_ENV:
    data_path = "../input/"  # Kaggle环境数据路径
else:
    data_path = ""  # 本地环境数据路径

# ==================== 数据加载部分 ====================
# 读取train数据集，并删除id列
df_train = pd.read_csv(data_path + "playground-series-s3e26/train.csv").drop(["id"], axis=1)
# 读取test数据集
df_test = pd.read_csv(data_path + "playground-series-s3e26/test.csv")
# 取出test数据集的id列备用
test_IDs = df_test.id
# 删除test数据集中的id列
df_test = df_test.drop("id", axis=1)
# 调整test数据集列顺序与train一致
df_test = df_test[df_train.columns[:-1]]
# 读取提交样例文件
df_sample_sub = pd.read_csv(data_path + "playground-series-s3e26/sample_submission.csv")

# 读取补充数据集，并调整列顺序与train一致
df_supp = pd.read_csv(data_path + "cirrhosis-patient-survival-prediction/cirrhosis.csv")[df_train.columns]

# 合并原始训练数据和补充数据，重置索引
df_train = pd.concat(objs=[df_train, df_supp]).reset_index(drop=True)

# ==================== 特征定义部分 ====================
LABEL = "Status"  # 目标变量列名
# 分类特征列表
CAT_FEATS = ["Drug", "Sex", "Ascites", "Hepatomegaly", "Spiders", "Edema", "Stage"]
# 数值特征列表(排除分类特征和目标变量)
NUM_FEATS = [x for x in df_train.columns if x not in CAT_FEATS and x != LABEL]
# 原始特征列表(除目标变量外的所有特征)
ORG_FEATS = df_train.drop(LABEL, axis=1).columns.tolist()

# 打印数据形状信息
print(f"Train shape: {df_train.shape}")
print(f"Test shape: {df_test.shape}")

# ==================== 数据探索分析(EDA)部分 ====================
# 生成描述性统计信息
desc_df = df_train.describe(include="all").T  # 转置以便更好查看
desc_df['unique'] = desc_df['unique'].fillna(df_train.nunique())  # 填充唯一值计数
desc_df['count'] = desc_df['count'].astype('int16')  # 转换计数列为整型
desc_df['missing'] = df_train.shape[0] - desc_df['count']  # 计算缺失值数量
desc_df  # 显示统计信息

# 生成数据报告(如果启用)
if GENERATE_REPORTS:
    profile = ProfileReport(df_train, title="YData Profiling Report - Cirrhosis")
    profile.to_notebook_iframe()

# 绘制目标变量分布饼图
status_counts = df_train[LABEL].value_counts()  # 计算各类别数量
labels = status_counts.index  # 获取类别标签
sizes = status_counts.values  # 获取各类别数量值
percentages = 100.0 * (sizes/sizes.sum())  # 计算百分比

plt.figure(figsize=(10, 6))  # 设置图形大小
plt.pie(sizes, labels=[f"{l}, {s:.1f}%" for l, s in zip(labels, percentages)], startangle=90)  # 绘制饼图
plt.gca().set_aspect("equal")  # 保持圆形
plt.legend(loc="upper right", bbox_to_anchor=(1.2, 1), labels=labels, title=LABEL)  # 添加图例
plt.title(f"Distribution of {LABEL}")  # 添加标题
plt.show()

# 绘制分类特征与目标变量的关系图
plt.figure(figsize=(14, len(CAT_FEATS) * 2))  # 设置图形大小
for i, col in enumerate(CAT_FEATS):
    plt.subplot(len(CAT_FEATS) // 2 + 1, 3, i + 1)  # 创建子图
    sns.countplot(x=col, hue=LABEL, data=df_train)  # 绘制计数条形图
    plt.title(f"{col} vs {LABEL}")  # 添加标题
    plt.tight_layout()  # 调整布局

# 绘制数值特征与目标变量的关系图(小提琴图)
fig, axes = plt.subplots(2, 3, figsize=(16, 10))  # 创建2行3列的子图
for i, ax in enumerate(axes.flatten()):
    sns.violinplot(x=LABEL, y=NUM_FEATS[i], data=df_train, ax=ax)  # 绘制小提琴图
    ax.set_title(f"{NUM_FEATS[i]} vs {LABEL}")  # 添加标题
plt.tight_layout()  # 调整布局
plt.show()

# ==================== 数据预处理部分 ====================
DATA_VERSION = 24  # 数据版本号

# 创建数据副本
df_train_mod = df_train.copy(deep=True)
df_test_mod = df_test.copy(deep=True)

print(f"Train shape: {df_train_mod.shape}")
print(f"Test shape: {df_test_mod.shape}")

# 找出有缺失值的分类特征
missing_cat = [f for f in df_train_mod.columns if df_train_mod[f].dtype == "O" if df_train_mod[f].isna().sum() > 0]

# CatBoost分类器参数配置(用于填补分类特征缺失值)
cat_params = {
    'depth': 6,
    'learning_rate': 0.1,
    'l2_leaf_reg': 0.7,
    'random_strength': 0.2,
    'max_bin': 200,
    'od_wait': 65,
    'one_hot_max_size': 70,
    'grow_policy': 'Depthwise',
    'bootstrap_type': 'Bayesian',
    'od_type': 'Iter',
    'eval_metric': 'MultiClass',
    'loss_function': 'MultiClass',
}

def store_missing_rows(df: pd.DataFrame, features: List[str]) -> Dict[str, pd.DataFrame]:
    """存储有缺失值的行
    参数:
        df: 数据框
        features: 特征列表
    返回:
        字典，键为特征名，值为该特征的缺失行数据框
    """
    missing_rows = {}
    for feature in features:
        missing_rows[feature] = df[df[feature].isnull()]
    return missing_rows

def fill_missing_categorical(train, test, target, features, max_iterations=10):
    """填补分类特征的缺失值
    参数:
        train: 训练数据
        test: 测试数据
        target: 目标变量名
        features: 要填补的特征列表
        max_iterations: 最大迭代次数
    返回:
        填补后的训练和测试数据
    """
    # 合并训练(不含目标变量)和测试数据
    df = pd.concat([train.drop(columns=target), test], axis="rows")
    df = df.reset_index(drop=True)
    
    # 存储缺失行信息
    missing_rows = store_missing_rows(df, features)
    
    # 用特殊值临时填充缺失值
    for f in features:
        df[f] = df[f].fillna("Missing_" + f)

    # 迭代填补
    for iteration in tqdm(range(max_iterations), desc="Iterations"):
        for feature in features:
            rows_miss = missing_rows[feature].index  # 缺失行索引
            missing_temp = df.loc[rows_miss].copy()  # 缺失数据临时副本
            non_missing_temp = df.drop(index=rows_miss).copy()  # 非缺失数据临时副本
            missing_temp = missing_temp.drop(columns=[feature])  # 移除当前特征列
            
            # 获取其他分类特征
            other_features = [x for x in df.columns if (x != feature and df[x].dtype == "O")]
            
            # 准备训练数据
            X_train = non_missing_temp.drop(columns=[feature])
            y_train = non_missing_temp[[feature]]
            
            # 训练CatBoost分类器
            catboost_classifier = CatBoostClassifier(**cat_params)
            catboost_classifier.fit(X_train, y_train, cat_features=other_features, verbose=False)
            
            # 预测缺失值
            y_pred = catboost_classifier.predict(missing_temp)
            if y_pred.dtype != "O":
                y_pred = y_pred.astype(str)

            df.loc[rows_miss, feature] = y_pred

    # 将填补后的数据分配回原始数据框
    train[features] = np.array(df.iloc[:train.shape[0]][features])
    test[features] = np.array(df.iloc[train.shape[0]:][features])

    return train, test

# 找出有缺失值的数值特征
missing_num = [f for f in df_train_mod.columns if df_train_mod[f].dtype != "O" and df_train_mod[f].isna().sum() > 0]

# CatBoost回归器参数配置(用于填补数值特征缺失值)
cb_params = {
    'iterations': 500,
    'depth': 6,
    'learning_rate': 0.02,
    'l2_leaf_reg': 0.5,
    'random_strength': 0.2,
    'max_bin': 150,
    'od_wait': 80,
    'one_hot_max_size': 70,
    'grow_policy': 'Depthwise',
    'bootstrap_type': 'Bayesian',
    'od_type': 'IncToDec',
    'eval_metric': 'RMSE',
    'loss_function': 'RMSE',
    'random_state': 42,
}

# LightGBM回归器参数配置(备选)
lgb_params = {
    'n_estimators': 50,
    'max_depth': 8,
    'learning_rate': 0.02,
    'subsample': 0.20,
    'colsample_bytree': 0.56,
    'reg_alpha': 0.25,
    'reg_lambda': 5e-08,
    'objective': 'multiclass',
    'metric': 'multi_logloss',
    'boosting_type': 'gbdt',
    'random_state': 42,
}

def rmse(y1, y2):
    """计算RMSE(均方根误差)"""
    return np.sqrt(mean_squared_error(y1, y2))

def fill_missing_numerical(train, test, target, features, max_iterations=10):
    """填补数值特征的缺失值
    参数:
        train: 训练数据
        test: 测试数据
        target: 目标变量名
        features: 要填补的特征列表
        max_iterations: 最大迭代次数
    返回:
        填补后的训练和测试数据
    """
    train_temp = train.copy()
    if target in train_temp.columns:
        train_temp = train_temp.drop(columns=target)
    
    # 合并训练(不含目标变量)和测试数据
    df = pd.concat([train_temp, test], axis="rows")
    df = df.reset_index(drop=True)
    
    # 存储缺失行信息
    missing_rows = store_missing_rows(df, features)
    
    # 用均值临时填充缺失值
    for f in features:
        df[f] = df[f].fillna(df[f].mean())
    
    # 获取分类特征
    cat_features = [f for f in df.columns if not pd.api.types.is_numeric_dtype(df[f])]
    dictionary = {feature: [] for feature in features}  # 存储RMSE变化
    
    # 迭代填补
    for iteration in tqdm(range(max_iterations), desc="Iterations"):
        for feature in features:
            rows_miss = missing_rows[feature].index  # 缺失行索引
            missing_temp = df.loc[rows_miss].copy()  # 缺失数据临时副本
            non_missing_temp = df.drop(index=rows_miss).copy()  # 非缺失数据临时副本
            y_pred_prev = missing_temp[feature]  # 前次预测值(用于比较)
            missing_temp = missing_temp.drop(columns=[feature])  # 移除当前特征列
            
            # 准备训练数据
            X_train = non_missing_temp.drop(columns=[feature])
            y_train = non_missing_temp[[feature]]
            
            # 训练模型(CatBoost回归器)
            model = CatBoostRegressor(**cb_params)
            model.fit(X_train, y_train, cat_features=cat_features, verbose=False)
            
            # 预测缺失值
            y_pred = model.predict(missing_temp)
            df.loc[rows_miss, feature] = y_pred
            error_minimize = rmse(y_pred, y_pred_prev)  # 计算RMSE变化
            dictionary[feature].append(error_minimize)  # 记录RMSE
    
    # 绘制RMSE变化曲线
    for feature, values in dictionary.items():
        iterations = range(1, len(values) + 1) 
        plt.plot(iterations, values, label=feature)
        plt.xlabel('Iterations')
        plt.ylabel('RMSE')
        plt.title('Minimization of RMSE with iterations')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.show()
    
    # 将填补后的数据分配回原始数据框
    train[features] = np.array(df.iloc[:train.shape[0]][features])
    test[features] = np.array(df.iloc[train.shape[0]:][features])

    return train, test

# 缺失值处理控制开关
DROP_MISSING = True

if DROP_MISSING:
    # 直接删除缺失值
    df_train_mod = df_train_mod.dropna()
    df_test_mod = df_test_mod.dropna()
else:
    # 使用模型预测填补缺失值
    df_train_mod, df_test_mod = fill_missing_categorical(df_train_mod, df_test_mod, LABEL, missing_cat, 5)
    df_train_mod, df_test_mod = fill_missing_numerical(df_train_mod, df_test_mod, LABEL, missing_num, 5)

# 对目标变量进行标签编码
label_encoder = LabelEncoder()
df_train_mod[LABEL] = label_encoder.fit_transform(df_train_mod[LABEL])

# 保存预处理后的数据
df_train_mod.to_csv(f"train_mod_v{DATA_VERSION}.csv")
df_test_mod.to_csv(f"test_mod_v{DATA_VERSION}.csv")

# ==================== 特征编码部分 ====================
# 定义各分类特征的编码方式
encoders = {
    # 顺序编码(指定类别顺序)
    'Drug': OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, categories=[['Placebo', 'D-penicillamine']]),
    # 顺序编码(自动确定类别顺序)
    'Sex': OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),
    'Ascites': OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),
    'Hepatomegaly': OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),
    'Spiders': OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),
    # 独热编码(适用于类别较少的特征)
    'Edema': OneHotEncoder(),
    # 顺序编码
    'Stage': OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
}

# 应用编码器
for feat, enc in encoders.items():
    if isinstance(enc, OrdinalEncoder):  # 顺序编码处理
        df_train_mod[feat] = enc.fit_transform(df_train_mod[[feat]]).astype('int32')
        df_test_mod[feat] = enc.transform(df_test_mod[[feat]]).astype('int32')
    
    if isinstance(enc, OneHotEncoder):  # 独热编码处理
        new_cols = enc.fit_transform(df_train_mod[[feat]]).toarray().astype('int8')
        col_names = enc.get_feature_names_out()
        
        # 添加新编码列并删除原始列
        df_train_mod[col_names] = new_cols
        df_train_mod.drop(feat, axis=1, inplace=True)
        
        # 对测试集同样处理
        new_cols_test = enc.transform(df_test_mod[[feat]]).toarray().astype('int8')
        df_test_mod[col_names] = new_cols_test
        df_test_mod.drop(feat, axis=1, inplace=True)

# 计算数值特征的均值和标准差(用于异常值检测)
df_train_mod[NUM_FEATS].mean()

# ==================== 异常值处理部分 ====================
# 创建数据副本
tmp_df = df_train_mod.copy()

# 计算数值特征的均值和标准差
means = tmp_df[NUM_FEATS].mean()
std_devs = tmp_df[NUM_FEATS].std()

n_stds = 6  # 设置标准差倍数阈值
thresholds = n_stds * std_devs  # 计算阈值

# 检测异常值(与均值差异超过n_stds倍标准差的样本)
outliers = (np.abs(tmp_df[NUM_FEATS] - means) > thresholds).any(axis=1)

print(f"Detected {sum(outliers)} that are more than {n_stds} SDs away from mean...")

# 提取异常值样本
outliers_df = tmp_df[outliers]

# 移除异常值并重置索引
df_train_mod = tmp_df[~outliers].reset_index(drop=True)
print(f"Train data shape after outlier removal: {df_train_mod.shape}")

# ==================== 模型训练与验证部分 ====================
from typing import List, Dict

def validate_models(models: List[Dict],
                   data: pd.DataFrame, 
                   label=LABEL,
                   n_splits=5,
                   n_repeats=1,
                   seed=43):
    """交叉验证评估模型性能
    参数:
        models: 模型列表(每个元素是包含name,model,feats的字典)
        data: 完整数据集
        label: 目标变量名
        n_splits: K折数
        n_repeats: 重复次数
        seed: 随机种子
    返回:
        更新后的模型列表, 训练分数DataFrame, 验证分数DataFrame
    """
    train_scores, val_scores = {}, {}  # 存储分数
    
    pbar = tqdm(models)  # 进度条
    for model in pbar:
        model_str = model["name"]  # 模型名称
        model_est = model["model"]  # 模型对象
        model_feats = model["feats"]  # 特征列表
        
        pbar.set_description(f"Processing {model_str}...")
        
        train_scores[model_str] = []
        val_scores[model_str] = []
        
        # 创建重复分层K折交叉验证对象
        skf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=seed)

        # 交叉验证循环
        for i, (train_idx, val_idx) in enumerate(skf.split(data[model_feats], data[label])):
            pbar.set_postfix_str(f"Fold {i+1}/{n_splits}")
            
            # 划分训练集和验证集
            X_train, y_train = data[model_feats].loc[train_idx], data[label].loc[train_idx]
            X_val, y_val = data[model_feats].loc[val_idx], data[label].loc[val_idx]
            
            # 模型特定训练设置
            if model_str in ["lgb_cl"]:  # LightGBM特有设置
                callbacks = [lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=0)]
                model_est.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks)
            elif model_str in ["xgb_cl", "cat_cl"]:  # XGBoost和CatBoost特有设置
                model_est.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)
            else:  # 其他模型
                model_est.fit(X_train, y_train)
            
            # 预测和评估
            train_preds = model_est.predict_proba(X_train[model_feats])
            valid_preds = model_est.predict_proba(X_val[model_feats])
            train_score = log_loss(y_train, train_preds)  # 训练集对数损失
            val_score = log_loss(y_val, valid_preds)  # 验证集对数损失
            train_scores[model_str].append(train_score)
            val_scores[model_str].append(val_score)
        
        # 计算平均验证分数
        model["avg_val_score"] = np.mean(val_scores[model_str])
            
    return models, pd.DataFrame(train_scores), pd.DataFrame(val_scores)

# XGBoost参数配置
xgb_params = {
    'objective': 'multi_logloss', 
    'early_stopping_rounds': 50, 
    'max_depth': 9, 
    'min_child_weight': 8, 
    'learning_rate': 0.0337716365315986, 
    'n_estimators': 733, 
    'subsample': 0.6927955384688348, 
    'colsample_bytree': 0.1234702658812108, 
    'reg_alpha': 0.18561628377665318, 
    'reg_lambda': 0.5565488299127089, 
    'random_state': 42
}

# 随机森林参数配置
rf_params = {'n_estimators': 200}

# 初始化模型
xgb_cl = xgb.XGBClassifier(**xgb_params)  # XGBoost分类器
rf_cl = RandomForestClassifier(**rf_params)  # 随机森林分类器

# 特征列表(排除目标变量)
FEATS = [c for c in df_train_mod.columns if c != LABEL]

# 模型配置列表
models = [
    {"name": "xgb_cl", "model": xgb_cl, "feats": FEATS},  # XGBoost模型配置
    {'name': "rf_cl", "model": rf_cl, "feats": FEATS}  # 随机森林模型配置
]

# 执行模型验证
models, train_scores, val_scores = validate_models(models=models, 
                                                 data=df_train_mod, 
                                                 n_splits=10,
                                                 n_repeats=1)

# 打印特征数量
len(FEATS)

# 测试预测(示例)
temp_array = np.random.rand(100, 20)
models[0]['model'].predict_proba(temp_array).shape

# 显示训练和验证分数
train_scores
val_scores
